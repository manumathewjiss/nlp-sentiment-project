â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
1. OVERALL ACCURACY COMPARISON
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

BERTweet (Imbalanced):
  Dataset Size: 18,214 comments
  Accuracy:     0.8581 (85.81%)

BERTweet (Balanced):
  Dataset Size: 13,322 comments
  Accuracy:     0.8124 (81.24%)

RoBERTa (Balanced):
  Dataset Size: 13,322 comments
  Accuracy:     0.8921 (89.21%)

RoBERTa (Imbalanced):
  Dataset Size: 18,214 comments
  Accuracy:     0.9023 (90.23%)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
2. PER-CLASS PERFORMANCE COMPARISON
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

NEGATIVE Sentiment:
Model                           Precision     Recall   F1-Score
----------------------------------------------------------------------
BERTweet (Imbalanced)               0.859      0.702      0.773
BERTweet (Balanced)                 0.932      0.696      0.797
RoBERTa (Balanced)                  0.950      0.873      0.910
RoBERTa (Imbalanced)                0.897      0.890      0.893

NEUTRAL Sentiment:
Model                           Precision     Recall   F1-Score
----------------------------------------------------------------------
BERTweet (Imbalanced)               0.681      0.848      0.755
BERTweet (Balanced)                 0.687      0.849      0.759
RoBERTa (Balanced)                  0.804      0.904      0.851
RoBERTa (Imbalanced)                0.759      0.904      0.825

POSITIVE Sentiment:
Model                           Precision     Recall   F1-Score
----------------------------------------------------------------------
BERTweet (Imbalanced)               0.949      0.894      0.921
BERTweet (Balanced)                 0.871      0.893      0.882
RoBERTa (Balanced)                  0.935      0.900      0.917
RoBERTa (Imbalanced)                0.976      0.904      0.939


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
3. MACRO-AVERAGED METRICS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Model                           Precision     Recall   F1-Score
----------------------------------------------------------------------
BERTweet (Imbalanced)               0.830      0.815      0.816
BERTweet (Balanced)                 0.830      0.813      0.813
RoBERTa (Balanced)                  0.897      0.892      0.893
RoBERTa (Imbalanced)                0.877      0.899      0.886


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
4. KEY INSIGHTS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

ðŸ“Š Dataset Balance Effect (BERTweet model):
   Imbalanced Dataset: 85.81%
   Balanced Dataset:   81.24%
   Difference:         +4.57% (4.57 percentage points)
   â†’ Imbalanced dataset achieved HIGHER accuracy
      (likely due to majority class bias)


ðŸ¤– Model Architecture Comparison (Balanced Dataset):
   BERTweet:  81.24%
   RoBERTa:   89.21%
   Difference: +7.96% (7.96 percentage points)
   â†’ RoBERTa performs BETTER than BERTweet
      RoBERTa correctly predicted 1060 more comments


ðŸ“ˆ Class-Specific Performance:

   Negative Detection:
      Best Model: RoBERTa (Balanced) (F1: 0.910)

   Neutral Detection:
      Best Model: RoBERTa (Balanced) (F1: 0.851)

   Positive Detection:
      Best Model: RoBERTa (Imbalanced) (F1: 0.939)


â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
5. RECOMMENDATIONS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

âœ… Recommended Model: RoBERTa (Imbalanced)
   Accuracy: 90.23%
   Reason: Highest overall accuracy

   RoBERTa also provides:
   â€¢ Balanced performance across all sentiment classes
   â€¢ Better handling of neutral sentiments
   â€¢ More recent training data (2018-2021)


======================================================================
END OF REPORT
======================================================================